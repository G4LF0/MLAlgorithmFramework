# -*- coding: utf-8 -*-
"""UsoFramework.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WxAGr9JvqJy4S5LyMirF25fseC-ySYQy

**Francisco Leonid Galvez Flores**

**A01174385**

[**Enlace al repositorio en GitHub**](https://github.com/G4LF0/MLAlgorithmFramework)

# **Librerias:**
"""

import pandas as pd
import numpy as np
import seaborn as sns

"""Importamos las librerias necesarias para algunos procesos a realizar antes de la implementacion del modelo.

# **Importacion de la base de datos:**
"""

url = "https://raw.githubusercontent.com/G4LF0/MLAlgorithmFramework/main/breast-cancer.csv"

df = pd.read_csv(url)
df.head(2)

"""Declaramos el dataframe con ayuda de la libreria de pandas, la base de datos se encuentra alojada en nuestro repositorio en GitHub.

# **Analisis exploratorio de los datos:**
"""

df.isnull().sum()

df.diagnosis = df.diagnosis.map({"M":1, "B":0})
df.shape

sns.set(rc = {'figure.figsize':(25,16)})
sns.heatmap(df.corr(), annot=True, cmap= 'YlGnBu')

df = df.drop(["id", "fractal_dimension_se","symmetry_se","smoothness_se","texture_se", "fractal_dimension_mean"], axis = 1)
df.head(1)

sns.set(rc = {'figure.figsize':(25,16)})
sns.heatmap(df.corr(), annot=True, cmap= 'YlGnBu')

"""En esta parte lo que hicimos fue analizar columnas que no tuvieran relacion con la variable a predecir, asi como tambien cambiamos el valor de algunos variables para convertirlas en binarias.

# **Division de los datos en trainig, validating and testing:**
"""

x = df.drop(["diagnosis"], axis = 1)
y = df.diagnosis

from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(x.values, y.values, train_size=0.9, random_state=16)

x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, train_size=0.7, random_state=16)

datos_n = [x_train.shape[0], x_val.shape[0], x_test.shape[0]]

df_mcd = pd.DataFrame({"Datos: ":["Training", "Validating", "Testing"],
                       "Registros": datos_n})
df_mcd

"""En esta parte lo que hacemos es divir el data set, al principio lo dividimos en un 90% para training y un 10% para test, despues lo que hacemos es que del 30% del 90% de training lo convertimos en validating.

# **Implementacion del modelo:**
"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

logreg = LogisticRegression(max_iter= 10000)
logreg.fit(x_train, y_train)
y_pred = logreg.predict(x_train)

"""Implementamos el algoritmo de regresion logistica con un numero de iteraciones maxima de 10,000.

Accuracy for training:
"""

score =accuracy_score(y_train,y_pred)
accuracy_training = score
print("Accuracy for the training set is: ", round(score*100, 4))

"""Accuracy for validating:"""

y_pred = logreg.predict(x_val)
score =accuracy_score(y_val,y_pred)
accuracy_validating = score
print("Accuracy for the training set is: ", round(score*100, 4))

"""Accuracy for testing"""

y_pred = logreg.predict(x_test)
score =accuracy_score(y_test,y_pred)
accuracy_testing = score
print("Accuracy for the training set is: ", round(score*100, 4))

"""# **Metricas:**

Metricas del training:
"""

from sklearn import metrics

y_pred = logreg.predict(x_train)
confusion_matrix = metrics.confusion_matrix(y_train, y_pred)
confusion_matrix

sns.heatmap(confusion_matrix, annot=True)

from sklearn.metrics import classification_report

target_names = ['Sin tumor', 'Con tumor']
print(classification_report(y_train, y_pred, target_names=target_names))

"""Metricas del validating:"""

from sklearn import metrics

y_pred = logreg.predict(x_val)
confusion_matrix = metrics.confusion_matrix(y_val, y_pred)
confusion_matrix

sns.heatmap(confusion_matrix, annot=True)

from sklearn.metrics import classification_report

target_names = ['Sin tumor', 'Con tumor']
print(classification_report(y_val, y_pred, target_names=target_names))

"""Metricas del testing:"""

from sklearn import metrics

y_pred = logreg.predict(x_test)
confusion_matrix = metrics.confusion_matrix(y_test, y_pred)
confusion_matrix

sns.heatmap(confusion_matrix, annot=True)

from sklearn.metrics import classification_report

target_names = ['Sin tumor', 'Con tumor']
print(classification_report(y_test, y_pred, target_names=target_names))

"""# **Curva ROC**

Training:
"""

y_pred_proba = logreg.predict_proba(x_train)[::,1]
fpr, tpr, _ = metrics.roc_curve(y_train,  y_pred_proba)
auc = metrics.roc_auc_score(y_train, y_pred_proba)
plt.plot(fpr,tpr,label="data 1, auc="+str(auc))
plt.legend(loc=4)
plt.show()

"""Validating:"""

y_pred_proba = logreg.predict_proba(x_val)[::,1]
fpr, tpr, _ = metrics.roc_curve(y_val,  y_pred_proba)
auc = metrics.roc_auc_score(y_val, y_pred_proba)
plt.plot(fpr,tpr,label="data 1, auc="+str(auc))
plt.legend(loc=4)
plt.show()

"""Testing:"""

y_pred_proba = logreg.predict_proba(x_test)[::,1]
fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)
auc = metrics.roc_auc_score(y_test, y_pred_proba)
plt.plot(fpr,tpr,label="data 1, auc="+str(auc))
plt.legend(loc=4)
plt.show()

"""Tenemos que decir que la curva ROC es un grafico en el que se ponen los valores positivos y falsos en cada eje, y como podemos ver dieron un muy buen accuracy en los tres datasets.

# **Tabla de accuracys:**
"""

df_accuracys = pd.DataFrame({"Datos: ":["Training", "Validating", "Testing"],
                             "Registros": [accuracy_training, accuracy_validating, accuracy_testing]})
df_accuracys

"""Como podemos ver nuestro modelo dispone de muy poco error en el dataset de training y mucho menos error en el dataset de validacion, por lo que decimos que se encuentra en **balance**.

# **Predicciones:**
"""

df.head(2)

df.tail(2)

"""Necesito retro de esto, entiendo que es generando un dataframe de prueba, pero como le especifico a la funcion el rango de valor minimo o maximo que puede tomar cada feature????"""

from sklearn.datasets import make_blobs
x_pred, _ = make_blobs(n_samples=5, centers=2, n_features=25, random_state=1)
y_pred = logreg.predict(x_pred)
for i in range(len(x_pred)):
  print("X=%s, Prediccion=%s" % (x_pred[i], y_pred[i]))

l = np.random.randint(low=0, high=52)
 x_pred = x_test[l:l+5]

y_pred = logreg.predict(x_pred)

y_pred

pd.DataFrame({"Numero de prediccion":["1", "2", "3", "4", "5"],
              "Prediccion":y_pred})

"""# **Conclusion:**

Si bien el dataset que le pasamos al algoritmo implementado era un dataset muy limpio al cual no le tuvimos que hacer una gran cantidad de modificaciones o transformacion, al implementar el algoritmo mediante un framework nos dimos cuenta que esto es mas facil que hacerlo a mano, de hecho, en la entrega anterior yo implemente este algoritmo a mano, [enlace](https://github.com/G4LF0/MLAlgorithmByHand).
En esta entrega el hecho de implementarlo con  un framewor facilita el estarle jugando a algunos parametros, por lo que hace esto mucho mas facil.
"""